{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommendation using Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is where algorithms attempt to make predictions about users interests by corraborating interests of other users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's a collaborative filtering recommendation system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collaborative filtering recommendation system makes predictions of what might interest a person based on the taste of many other users. It assumes that if person X likes comedy movies, and person Y likes comedy movies and family movies, then person X might like family movies as well. There are two types of this recommender filter:\n",
    "\n",
    "**User-User**: It identifies other people with similar tastes to a target user and combines their ratings to make recommendations for that user.\n",
    "\n",
    "**Item-Item**: It identifies global product associations from items, but uses these product associations to provide personalized recommendations based on a user's own product ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will attempt to implement an **item-based** and **user-based** collaborative recommender and evaluate it using **Root Mean Square Error** (RSME) to see how well it performs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this dataset at https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')# read in ratings dataset\n",
    "movies = pd.read_csv('movies.csv')# read in movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(ratings,movies,on = 'movieId').drop(['timestamp','genres'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pivot = new_df.pivot_table(values = 'rating', index = 'userId', columns = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's identify the movies each user have rated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = {}\n",
    "rows_indexes = {}\n",
    "for i,row in missing_pivot.iterrows():\n",
    "    rows = [x for x in range(0,len(missing_pivot.columns))]\n",
    "    combine = list(zip(row.index, row.values, rows))\n",
    "    rated = [(x,z) for x,y,z in combine if str(y) != 'nan']\n",
    "    index = [i[1] for i in rated]\n",
    "    row_names = [i[0] for i in rated]\n",
    "    rows_indexes[i] = index\n",
    "    rate[i] = row_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are their rated movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the user-item matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = new_df.pivot_table(values = 'rating', index = 'userId', columns = 'title').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pivot_table.apply(np.sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies not rated by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notrated = {}\n",
    "notrated_indexes = {}\n",
    "for i,row in pivot_table.iterrows():\n",
    "    rows = [x for x in range(0,len(missing_pivot.columns))]\n",
    "    combine = list(zip(row.index, row.values, row))\n",
    "    idx_row = [(idx,col) for idx, val, col in combine if not val > 0]\n",
    "    indices = [i[1] for i in idx_row]\n",
    "    row_names = [i[0] for i in idx_row]\n",
    "    notrated_indexes[i] = indices\n",
    "    notrated[i] = row_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notrated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Unsupervised Nearest Neighbor Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "item_cosine_nn = NearestNeighbors(n_neighbors = n,algorithm = 'brute', metric = 'correlation')\n",
    "item_cosine_nn_fit = item_cosine_nn.fit(pivot_table.T.values)\n",
    "item_distances, item_indices = item_cosine_nn_fit.kneighbors(pivot_table.T.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dic = {}\n",
    "for i in range(len(pivot_table.T.index)):\n",
    "    item_idx = item_indices[i]\n",
    "    col_names = pivot_table.T.index[item_idx].tolist()\n",
    "    items_dic[pivot_table.T.index[i]] = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRecs = {}\n",
    "for k,v in rows_indexes.items():\n",
    "    item_idx = [j for i in item_indices[v] for j in i]\n",
    "    item_dist = [j for i in item_distances[v] for j in i]\n",
    "    combine = list(zip(item_idx,item_dist))\n",
    "    unique = {i:d for i,d in combine if i not in v}\n",
    "    sort = sorted(unique.items(), key = lambda x: x[1])\n",
    "    col_names = [(pivot_table.columns[i[0]],i[1]) for i in sort]\n",
    "    topRecs[k] = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrecommendations(user, number_of_recs = 30):\n",
    "    if user > len(pivot_table.index):\n",
    "        print('Out of range, there are only {} users, try again!'.format(len(pivot_table.index)))\n",
    "    else:\n",
    "        \n",
    "        print(\"These are all the movies you have viewed view in the past: \\n\\n{}\".format('\\n'.join(rate[user])))\n",
    "        print()\n",
    "        print(\"We recommend to view these movies too:\\n\")\n",
    "    for k,v in topRecs.items():\n",
    "        if user == k:\n",
    "            for i in v[:number_of_recs]:\n",
    "                print('{} with similarity: {:.4f}'.format(i[0], 1 - i[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getrecommendations(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **These recommendations make sense to me!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cosine_nn = NearestNeighbors(n_neighbors = n,algorithm = 'brute', metric = 'correlation')\n",
    "user_cosine_nn_fit = user_cosine_nn.fit(pivot_table.values)\n",
    "user_distances, user_indices = user_cosine_nn_fit.kneighbors(pivot_table.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = {}\n",
    "for i in range(len(pivot_table.index)):\n",
    "    user_dist = user_distances[i]\n",
    "    user_idx = user_indices[i]\n",
    "    users[i+1] = np.array(pivot_table.index)[user_idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTop = {}\n",
    "for k,v in topRecs.items():\n",
    "    newTop[k] = [i[0] for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = {}\n",
    "for k,v in users.items():\n",
    "    users_item = {i:val[:20] for i in v[1:] for key, val in newTop.items() if i == key}\n",
    "    userRecs[k] = users_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make predictions for the movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_distances = 1 - item_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_predictions = item_distances.T.dot(pivot_table.T.values) / np.array([np.abs(item_distances.T).sum(axis = 1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ground_truth = pivot_table.T.values[item_indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make predictions for the users!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_distances = 1 - user_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_predictions = user_distances.T.dot(pivot_table.values)/ np.array([np.abs(user_distances.T).sum(axis = 1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ground_truth = pivot_table.values[user_indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the recommender's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Item-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_error_rate = rmse(item_predictions,item_ground_truth)\n",
    "print(\"Accuracy: {:.3f}\".format(100 - item_error_rate))\n",
    "print(\"RMSE: {:.5f}\".format(item_error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the User-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_error_rate = rmse(user_predictions,user_ground_truth)\n",
    "print(\"Accuracy: {:.3f}\".format(100 - user_error_rate))\n",
    "print(\"RMSE: {:.5f}\".format(user_error_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
